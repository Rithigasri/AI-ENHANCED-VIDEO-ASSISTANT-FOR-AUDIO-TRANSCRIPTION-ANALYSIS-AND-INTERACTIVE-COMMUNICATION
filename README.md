<h1 align="center">AI-ENHANCED VIDEO ASSISTANT FOR  AUDIO TRANSCRIPTION, ANALYSIS, AND INTERACTIVE COMMUNICATION</h1>
This project develops an AI-powered video assistant that automates transcription, summarization, and Q&A functionalities for video content. It uses advanced technologies like OpenAI Whisper for speech-to-text, Hugging Face Transformers for summarization, and Google Text-to-Speech for auditory feedback. The assistant improves efficiency in interacting with videos across domains like education and business. It also supports multiple languages and enhances accessibility for diverse users.

## About
This project introduces an AI-powered video assistant designed to enhance user interaction with video content by automating transcription, summarization, and question-answering. It leverages advanced technologies such as OpenAI's Whisper for accurate speech-to-text conversion, Hugging Face Transformers for summarization and Q&A, and Google Text-to-Speech (gTTS) for audio feedback. The assistant significantly improves productivity by providing quick insights from lengthy videos, making it highly useful for sectors like education, business, and content creation. It also offers multilingual support, ensuring accessibility for a global audience. The system is built for scalability, with potential future enhancements like real-time interaction and personalized recommendations.

## Features
* **Automatic Transcription:** Converts video audio into text using OpenAI Whisper.
* **Text Summarization:** Generates concise summaries of long video content.
* **Q&A Functionality:** Provides answers to user queries based on the transcribed content.
* **Multilingual Support:** Offers transcription, translation, and speech output in multiple languages.
* **Text-to-Speech:** Converts text-based responses into natural-sounding speech.
* **User-Friendly Interface:** Built with Flask and React, allowing easy video uploads and interaction.
* **Scalability:** Supports future enhancements like real-time interaction and personalization.

## Requirements
### Hardware:
* **Processor:** Intel Core i5 or equivalent.
* **RAM:** Minimum 8 GB for smooth processing.
* **Storage:** 256 GB SSD or higher.
* **Graphics:** NVIDIA GeForce GTX 1050 or higher (for deep learning tasks).
### Software:
* **Operating System:** Windows 10 or 11 (64-bit).
* **Programming Language:** Python 3.8 or higher.
* **Libraries & Frameworks:**
Flask (Backend), React (Frontend).
MoviePy, Whisper, Hugging Face Transformers, Google TTS.
* **Development Tools:** PyCharm or Visual Studio Code for code development and debugging.
  
## System Architecture
![API Gateway](https://github.com/user-attachments/assets/e3cd2921-95fe-48ac-845c-01a488e4f6ca)

## Output
### Video Upload and Transcription
![AD_4nXcGwjrIF6Xx5dQHxZBsM0NBA0DONZmR1w5A7iVN4Yw1O0Awy0PrMaigXolGCzrng_Nvv-paMkxeaIKKMe8ZDDsknyfaML4sZ1LY4usYo4DZcexA0wCXFsAt](https://github.com/user-attachments/assets/d4cd961d-7255-40e6-9fc0-2becd7a05f9f)

### Summarization Output
![AD_4nXdvyhN-9TffwfYgaro5co5W2hG9pib5Cd-rDvqksK_kxvFHg1C7cgBWiNzJWnAqXtKuSBjTBw95sX823TUpnMw7VUq8hmWiPY-495U7gSVPCybZlZXDgLJ5](https://github.com/user-attachments/assets/9a783de6-4a04-49ec-a861-5ff3a109ab1e)

### Question - Answering Feature
![Ask a Question](https://github.com/user-attachments/assets/3ea5b3d4-e436-407e-80e9-941fad144b63)

### Multilingual Translation Output
![Ask a Question](https://github.com/user-attachments/assets/b74015af-fad7-4a79-a6f1-e7fd752ea62c)

### Key Moments Frame Extraction
![Key Moments](https://github.com/user-attachments/assets/45479770-6c07-4184-be13-ffdeaf47c70d)

![HOW TO LOGIN](https://github.com/user-attachments/assets/ec9e41d2-fe0b-4761-9cc7-1145c2c50969)

## Results and Impact
The AI Video Assistant achieved high accuracy in transcription (~90-95%), summarization (~85-90%), and question-answering (~80-85%), enhancing efficiency in video content analysis. It significantly reduces manual effort, improves accessibility with multilingual support, and allows users to quickly extract key insights from videos. This makes it valuable for education, business, and content creation sectors, enhancing productivity and user engagement.

## Articles published / References
[1] R. Benny, A. Muralidharan and M. Subramanian, "OpenAI-Enhanced Personal Desktop Assistant: A Revolution in Human-Computer Interaction," 2024 Second International Conference on Emerging Trends in Information Technology and Engineering (ICETITE), Vellore, India, 2024, pp. 1-7, doi: 10.1109/ic-ETITE58242.2024.10493339.
[2] I. Aljarrah and D. Mohammad, "Video content analysis using convolutional neural networks," 2018 9th International Conference on Information and Communication Systems (ICICS), Irbid, Jordan, 2018, pp. 122-126, doi: 10.1109/IACS.2018.8355453.
[3] V. M. Reddy, T. Vaishnavi and K. P. Kumar, "Speech-to-Text and Text-to-Speech Recognition Using Deep Learning," 2023 2nd International Conference on Edge Computing and Applications (ICECAA), Namakkal, India, 2023, pp. 657-666, doi: 10.1109/ICECAA58104.2023.10212222.
[4] Patil, Gayatri & Saravanan, Krithika & Sapariya, Bhakti & Gotarne, Prajakta. (2024). Chrome Extension for Speech-to-Text Conversion and Text Summarization Using NLP. 1-7. 10.1109/ICITEICS61368.2024.10624940. 
[5]  A. Kumar, S. Verma and H. Mangla, "A Survey of Deep Learning Techniques in Speech Recognition," 2018 International Conference on Advances in Computing, Communication Control and Networking (ICACCCN), Greater Noida, India, 2018, pp. 179-185, doi: 10.1109/ICACCCN.2018.8748399.
[6] Rehman, Atiq & Brahim Belhaouari, Samir. (2021). Deep Learning for Video Classification: A Review. 10.36227/techrxiv.15172920.v1.
[7] Barakat, H., Turk, O. & Demiroglu, C. Deep learning-based expressive speech synthesis: a systematic review of approaches, challenges, and resources. J AUDIO SPEECH MUSIC PROC. 2024, 11 (2024). https://doi.org/10.1186/s13636-024-00329-7
